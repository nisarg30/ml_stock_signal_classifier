{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read data from csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "min_length = min(len(xxc), len(xxl))\n",
        "print(\"Minimum length:\", min_length)\n",
        "\n",
        "# Truncate both sequences to the minimum length\n",
        "xxc_truncated = xxc[:min_length]\n",
        "xxl_truncated = xxl[:min_length]\n",
        "\n",
        "# Assuming y is a 1D array\n",
        "yy = y\n",
        "\n",
        "# Convert NumPy arrays to DataFrame columns\n",
        "xx = pd.DataFrame({'s': xxc_truncated[:, 0], 'l': xxl_truncated[:, 0]})\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(xx, yy, test_size=0.5, random_state=42)\n",
        "\n",
        "# Initialize and train the logistic regression model\n",
        "modeld.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing set\n",
        "y_pred = modeld.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Print confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsX58kd_OQER"
      },
      "source": [
        "Calculate derivatives using talib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "VaINtTs1OPOZ",
        "outputId": "d2bc11e0-6b5a-4a80-e4b8-bf2227e136fa"
      },
      "outputs": [],
      "source": [
        "import pandas_ta as ta\n",
        "import pandas as pd\n",
        "\n",
        "def add_technical_indicators(filename):\n",
        "    df = pd.read_csv(filename)\n",
        "\n",
        "    # Reverse DataFrame\n",
        "    df = df[::-1]\n",
        "\n",
        "    # EMA\n",
        "    df['ema_20'] = ta.ema(df['Close'], length=20)\n",
        "    df['ema_50'] = ta.ema(df['Close'], length=50)\n",
        "\n",
        "    # RSI\n",
        "    df['rsi'] = ta.rsi(df['Close'], length=14)\n",
        "\n",
        "    # MACD\n",
        "    df['macd'] = ta.macd(df['Close'])['MACD_12_26_9']  # MACD line\n",
        "    df['signal_line'] = ta.macd(df['Close'])['MACDs_12_26_9']   # Signal line\n",
        "\n",
        "    # BBands\n",
        "    bbands = ta.bbands(df['Close'], length=20, std=2)\n",
        "    df['upper_band'] = bbands['BBU_20_2.0']\n",
        "    df['middle_band'] = bbands['BBM_20_2.0']\n",
        "    df['lower_band'] = bbands['BBL_20_2.0']\n",
        "\n",
        "    return df\n",
        "\n",
        "# Example usage:\n",
        "filename = '/home/ghost-bot/Desktop/trigger/datax/BANKNIFTY_1.csv'\n",
        "df = add_technical_indicators(filename)\n",
        "df = df[::-1]\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05TuiJ-VOduF"
      },
      "source": [
        "Classify labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdQYsDtrPwEE"
      },
      "source": [
        "calculate difference === feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Xzf3RxwMPKZe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Calculate new columns\n",
        "df['wvff'] = df['wvf'] - df['rangeHigh']\n",
        "df['ema'] = df['ema_20'] - df['ema_50']\n",
        "df['cema'] = df['Close'] - df['ema_20']\n",
        "df['lowc'] = df['Close'] - df['lower_band']\n",
        "df['macdf'] = df['macd'] - df['signal_line']\n",
        "df['midlc'] = df['Close'] - df['middle_band']\n",
        "df['wvflf'] = df['wvfl'] - df['rangeHighl']\n",
        "\n",
        "data = df.drop(columns=['Volume','Open','Max','Min','wvf','rangeHigh','wvfl','rangeHighl','ema_20', 'ema_50','macd','signal_line','upper_band','lower_band','middle_band'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hJzCwa8Q09M"
      },
      "source": [
        "row difference calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "yjTbvJzkQ0Ks",
        "outputId": "91fcc869-b04e-4fca-cf10-a820c07ea9f4"
      },
      "outputs": [],
      "source": [
        "xx = data.copy()\n",
        "xx = xx.drop(columns=['Entry'])\n",
        "xx = xx[::-1]\n",
        "df_diff = xx.diff().fillna(0)\n",
        "df_diff = df_diff[::-1]\n",
        "xx = xx[::-1]\n",
        "df_diff['Entry'] = data['Entry']\n",
        "\n",
        "for col in xx.columns[1:]:\n",
        "    xx[col + '_diff'] = df_diff[col]\n",
        "\n",
        "# data.drop(columns=['Entry_diff'])\n",
        "xx['Entry'] = data['Entry']\n",
        "# xx = xx\n",
        "xx.tail()\n",
        "# data = xx.copy()\n",
        "# df_diff.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPI-F5G3RE_n"
      },
      "source": [
        "data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQ5agEg7ba5P",
        "outputId": "1aeb5d8a-d650-42eb-8518-3a93f7e0b22f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# data = pd.read_csv('/content/xyz.csv', index_col=0)\n",
        "df = data\n",
        "df = df.dropna()\n",
        "\n",
        "x = df.drop(columns=['Timestamp', 'Entry'])\n",
        "\n",
        "features = x.columns.tolist()\n",
        "features.remove('Close')\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(-100, 100))\n",
        "\n",
        "sequences = []\n",
        "labels = []\n",
        "original_indices = []\n",
        "\n",
        "for i in range(len(df) - 60):\n",
        "    current_label = df['Entry'].iloc[i]\n",
        "    if current_label != 2:\n",
        "        original_indices.append(i)\n",
        "        sequence_scaled = df[features].iloc[i:i+61].apply(lambda x: scaler.fit_transform(x.values.reshape(-1, 1)).flatten(), axis=0).values.tolist()\n",
        "        close_scaler = MinMaxScaler(feature_range=(-100, 100))\n",
        "        close_scaled = close_scaler.fit_transform(df['Close'].iloc[i:i+61].values.reshape(-1, 1)).flatten().tolist()\n",
        "        sequence_scaled = [[close] + scaled_features for close, scaled_features in zip(close_scaled, sequence_scaled)]\n",
        "        sequences.append(sequence_scaled)\n",
        "        labels.append(current_label)\n",
        "\n",
        "sequences_reversed = [seq[::-1] for seq in sequences]\n",
        "\n",
        "X = sequences_reversed\n",
        "y = labels\n",
        "\n",
        "corresponding_rows = [df.iloc[idx:idx+61] for idx in original_indices]\n",
        "\n",
        "print(len(X[0][0]))\n",
        "print(len(y))\n",
        "print(X[0][0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDmLRNsgYF5c",
        "outputId": "fdaf4d59-16b8-472f-c8e9-295846bd0b3b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# data = pd.read_csv('/content/xyz.csv', index_col=0)\n",
        "df = df_diff\n",
        "df = df.dropna()\n",
        "\n",
        "x = df.drop(columns=['Timestamp', 'Entry'])\n",
        "\n",
        "features = x.columns.tolist()\n",
        "features.remove('Close')\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(-100, 100))\n",
        "\n",
        "sequences = []\n",
        "labels = []\n",
        "original_indices = []\n",
        "\n",
        "for i in range(len(df) - 60):\n",
        "    current_label = df['Entry'].iloc[i]\n",
        "    if current_label != 2:\n",
        "        original_indices.append(i)\n",
        "        sequence_scaled = df[features].iloc[i:i+61].apply(lambda x: scaler.fit_transform(x.values.reshape(-1, 1)).flatten(), axis=0).values.tolist()\n",
        "        close_scaler = MinMaxScaler(feature_range=(-100, 100))\n",
        "        close_scaled = close_scaler.fit_transform(df['Close'].iloc[i:i+61].values.reshape(-1, 1)).flatten().tolist()\n",
        "        sequence_scaled = [[close] + scaled_features for close, scaled_features in zip(close_scaled, sequence_scaled)]\n",
        "        sequences.append(sequence_scaled)\n",
        "        labels.append(current_label)\n",
        "\n",
        "sequences_reversed = [seq[::-1] for seq in sequences]\n",
        "\n",
        "Xx = sequences_reversed\n",
        "yx = labels\n",
        "\n",
        "corresponding_rows = [df.iloc[idx:idx+61] for idx in original_indices]\n",
        "\n",
        "print(len(Xx[0][0]))\n",
        "print(len(yx))\n",
        "print(Xx[0][0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaOLtLFmR97o"
      },
      "source": [
        "model prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1zqR7-oR6d8",
        "outputId": "91d56e69-ed0d-4273-afbb-f56cc2e30c92"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Dropout\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Bidirectional(LSTM(128, return_sequences=True), input_shape=(61, 9)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "# model.add(Dropout(0.4))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "# model.add(Dropout(0.2))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "# model.add(Dropout(0.2))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(32)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_acc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIII6vTlSBMO"
      },
      "source": [
        "results and confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rM8kJH7aSBXG",
        "outputId": "aec35c9b-bb4b-4bfa-8ba7-1b888ce5e2e4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
        "\n",
        "X1 = X\n",
        "y1 = y\n",
        "\n",
        "xxc = model.predict(X1)\n",
        "predictions = (xxc > 0.5).astype(\"int32\")\n",
        "\n",
        "conf_matrix1 = confusion_matrix(y1, predictions)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix1)\n",
        "\n",
        "accuracy = accuracy_score(y1, predictions)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "precision = precision_score(y1, predictions, zero_division=1)\n",
        "print(\"Precision:\", precision)\n",
        "\n",
        "recall = recall_score(y1, predictions, zero_division=1)\n",
        "print(\"Recall:\", recall)\n",
        "\n",
        "# Printing predicted vs original values\n",
        "# print(\"\\nPredicted vs Original Values:\")\n",
        "# for i in range(len(predictions)):\n",
        "#     print(f\"Predicted: {predictions[i]}, Original: {y1[i]}, data: {df.iloc[original_indices[i]]['Timestamp']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-QNAKqPd1Vs",
        "outputId": "c188009a-4e8d-4a49-a20d-e4942872ca6d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
        "\n",
        "X1 = np.array(Xx)\n",
        "y1 = np.array(yx)\n",
        "\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(LSTM(128, return_sequences=True, input_shape=(61, 9)))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(LSTM(64, return_sequences=True))\n",
        "model2.add(LSTM(64, return_sequences=True))\n",
        "# model2.add(LSTM(64, return_sequences=True))\n",
        "model2.add(LSTM(64, return_sequences=True))\n",
        "model2.add(LSTM(64, return_sequences=True))\n",
        "model2.add(LSTM(32))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model2.fit(X_train1, y_train1, epochs=20, batch_size=32)\n",
        "\n",
        "test_loss, test_acc = model2.evaluate(X_test1, y_test1)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_acc)\n",
        "\n",
        "# all_weights = []\n",
        "# all_biases = []\n",
        "# for layer in model.layers:\n",
        "#     if hasattr(layer, 'weights'):\n",
        "#         weights = layer.get_weights()\n",
        "#         if len(weights) > 0:\n",
        "#             all_weights.append(weights[0])\n",
        "#             all_biases.append(weights[1])\n",
        "\n",
        "# print(all_weights)\n",
        "# print(all_biases)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VD17yfq6U--y",
        "outputId": "146a317c-46bd-450f-99e0-f9f4118331bc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
        "\n",
        "# Assuming Xx and yx are your input features and labels\n",
        "X1 = np.array(Xx)  # Ensure X1 is a NumPy array\n",
        "y1 = np.array(yx)  # Ensure y1 is a NumPy array\n",
        "\n",
        "# Check the shape of the input data\n",
        "print(\"Shape of X1:\", X1.shape)\n",
        "\n",
        "# Make predictions\n",
        "xxl = model2.predict(X1)\n",
        "\n",
        "# Convert predictions to binary class labels\n",
        "predictionsl = (xxl > 0.5).astype(\"int32\")\n",
        "\n",
        "# Compute confusion matrix\n",
        "conf_matrix1 = confusion_matrix(y1, predictionsl)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix1)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y1, predictionsl)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(y1, predictionsl, zero_division=1)\n",
        "print(\"Precision:\", precision)\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(y1, predictionsl, zero_division=1)\n",
        "print(\"Recall:\", recall)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x80xr4ODlUzX",
        "outputId": "7cf5be6a-0265-4768-d5bf-04557412a35e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Determine the minimum length among the sequences\n",
        "min_length = min(len(xxc), len(xxl))\n",
        "print(\"Minimum length:\", min_length)\n",
        "\n",
        "# Truncate both sequences to the minimum length\n",
        "xxc_truncated = xxc[:min_length]\n",
        "xxl_truncated = xxl[:min_length]\n",
        "\n",
        "# Assuming y is a 1D array\n",
        "yy = y\n",
        "\n",
        "# Convert NumPy arrays to DataFrame columns\n",
        "xx = pd.DataFrame({'s': xxc_truncated[:, 0], 'l': xxl_truncated[:, 0]})\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(xx, yy, test_size=0.6, random_state=42)\n",
        "\n",
        "# Initialize and train the logistic regression model\n",
        "modeld = LogisticRegression()\n",
        "modeld.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing set\n",
        "y_pred = modeld.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Print confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tmujeXJ4Z7Z"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('./models/nifty_models_1min/NIFTY_1_bilstm_model.keras')\n",
        "model2 = load_model('./models/nifty_models_1min/NIFTY_1_lstm_model.keras')\n",
        "modeld = joblib.load('./models//nifty_models_1min/NIFTY_1_log_model.joblib')\n",
        "\n",
        "stockname  = \"NIFTY\"\n",
        "timeframe = \"1\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "20WKnCA44Rvw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Define the path to save the model\n",
        "save_path = './models/banknifty_models_1min/BANKNIFTY_1_bilstm_model.keras'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "\n",
        "# Save the model\n",
        "# model.save(save_path)\n",
        "\n",
        "model.save('./models/banknifty_models_1min/BANKNIFTY_1_bilstm_model.keras') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "S6PlIHv84R6Z"
      },
      "outputs": [],
      "source": [
        "model2.save('./models/banknifty_models_1min/BANKNIFTY_1_lstm_model.keras')  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3L_GoFAU4SGK",
        "outputId": "88780960-fa96-4c62-d35d-f081dd6d973c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['./models/banknifty_models_1min/BANKNIFTY_1_log_model.joblib']"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from joblib import dump\n",
        "\n",
        "dump(modeld, './models/banknifty_models_1min/BANKNIFTY_1_log_model.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xP8YeTh_GBA9"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# Load the model\n",
        "modelx = load_model('/content/NIFTY_5_model.h5', custom_objects=None, compile=True, safe_mode=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SK1zz-dGTi-",
        "outputId": "febe0604-e411-4627-a075-ad58e0adba2b"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
        "pred = modelx.predict(X_test)\n",
        "predictions = (pred > 0.50).astype(\"int32\")\n",
        "\n",
        "X1 = X_test\n",
        "y1 = y_test\n",
        "\n",
        "conf_matrix1 = confusion_matrix(y1, predictions)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix1)\n",
        "\n",
        "accuracy = accuracy_score(y1, predictions)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "precision = precision_score(y1, predictions, zero_division=1)\n",
        "print(\"Precision:\", precision)\n",
        "\n",
        "recall = recall_score(y1, predictions, zero_division=1)\n",
        "print(\"Recall:\", recall)\n",
        "# conf_matrix = confusion_matrix(y, xyz)\n",
        "# print(conf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fOvwLNeIu6B",
        "outputId": "dda334ea-698e-459c-e24d-2c24f9aa28bf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Dropout\n",
        "import talib\n",
        "\n",
        "def add_technical_indicators(df):\n",
        "    close_pricesx = df['Close'].values\n",
        "    close_prices = close_pricesx[::-1]\n",
        "    ema_20 = talib.EMA(close_prices, timeperiod=20)\n",
        "    ema_50 = talib.EMA(close_prices, timeperiod=50)\n",
        "    rsi = talib.RSI(close_prices, timeperiod=14)\n",
        "    macd, signal_line, _ = talib.MACD(close_prices)\n",
        "    upper_band, middle_band, lower_band = talib.BBANDS(close_prices, timeperiod=20, nbdevup=2, nbdevdn=2)\n",
        "    df['ema_20'] = ema_20[::-1]\n",
        "    df['ema_50'] = ema_50[::-1]\n",
        "    df['rsi'] = rsi[::-1]\n",
        "    df['macd'] = macd[::-1]\n",
        "    df['signal_line'] = signal_line[::-1]\n",
        "    df['upper_band'] = upper_band[::-1]\n",
        "    df['middle_band'] = middle_band[::-1]\n",
        "    df['lower_band'] = lower_band[::-1]\n",
        "    return df\n",
        "\n",
        "def calculate_new_columns(df):\n",
        "    df['wvff'] = df['wvf'] - df['rangeHigh']\n",
        "    df['ema'] = df['ema_20'] - df['ema_50']\n",
        "    df['cema'] = df['Close'] - df['ema_20']\n",
        "    df['lowc'] = df['Close'] - df['lower_band']\n",
        "    df['macdf'] = df['macd'] - df['signal_line']\n",
        "    df['midlc'] = df['Close'] - df['middle_band']\n",
        "    df['wvflf'] = df['wvfl'] - df['rangeHighl']\n",
        "    return df.drop(columns=['Volume','Open','Max','Min','wvf','rangeHigh','wvfl','rangeHighl','ema_20', 'ema_50','macd','signal_line','upper_band','lower_band','middle_band'])\n",
        "\n",
        "def load_data(filename):\n",
        "    data = pd.read_csv(filename, index_col=0)\n",
        "    df_with_indicators = add_technical_indicators(data)\n",
        "    df_processed = calculate_new_columns(df_with_indicators)\n",
        "    df = df_processed.dropna()\n",
        "    x = df.drop(columns=['Entry'])\n",
        "    features = x.columns.tolist()\n",
        "    features.remove('Close')\n",
        "    scaler = MinMaxScaler(feature_range=(-100, 100))\n",
        "    sequences = []\n",
        "    labels = []\n",
        "    for i in range(len(df) - 60):\n",
        "        current_label = df['Entry'].iloc[i]\n",
        "        if current_label != 2:\n",
        "            sequence_scaled = df[features].iloc[i:i+61].apply(lambda x: scaler.fit_transform(x.values.reshape(-1, 1)).flatten(), axis=0).values.tolist()\n",
        "            close_scaler = MinMaxScaler(feature_range=(-100, 100))\n",
        "            close_scaled = close_scaler.fit_transform(df['Close'].iloc[i:i+61].values.reshape(-1, 1)).flatten().tolist()\n",
        "            sequence_scaled = [[close] + scaled_features for close, scaled_features in zip(close_scaled, sequence_scaled)]\n",
        "            sequences.append(sequence_scaled)\n",
        "            labels.append(current_label)\n",
        "    sequences_reversed = [seq[::-1] for seq in sequences]\n",
        "    X = sequences_reversed\n",
        "    y = labels\n",
        "    return X, y\n",
        "\n",
        "def train_model(X, y):\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(LSTM(128, return_sequences=True), input_shape=(61, 9)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "    model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "    model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "    model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "    model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "    model.add(Bidirectional(LSTM(32)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=0)\n",
        "\n",
        "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "    print(\"Test Loss:\", test_loss)\n",
        "    print(\"Test Accuracy:\", test_acc)\n",
        "\n",
        "    return model, X_test, y_test\n",
        "\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    xxc = model.predict(X_test)\n",
        "    predictions = (xxc > 0.8).astype(\"int32\")\n",
        "    conf_matrix1 = confusion_matrix(y_test, predictions)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(conf_matrix1)\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    precision = precision_score(y_test, predictions, zero_division=1)\n",
        "    print(\"Precision:\", precision)\n",
        "    recall = recall_score(y_test, predictions, zero_division=1)\n",
        "    print(\"Recall:\", recall)\n",
        "    return accuracy, precision, recall\n",
        "\n",
        "def save_model(model, filename):\n",
        "    model.save(f'{filename}.h5')\n",
        "    print(f\"Model saved as {filename}.h5\")\n",
        "\n",
        "def process_stock_data(stockname_timeframe):\n",
        "    filename = f'{stockname_timeframe}.csv'\n",
        "    X, y = load_data(filename)\n",
        "    trained_model, X_test, y_test = train_model(X, y)\n",
        "    accuracy, precision, recall = evaluate_model(trained_model, X_test, y_test)\n",
        "    save_model(trained_model, f'{stockname_timeframe}_model')\n",
        "    return accuracy, precision, recall\n",
        "\n",
        "# Example usage:\n",
        "stockname_timeframe = '/content/NIFTY_5'\n",
        "accuracy, precision, recall = process_stock_data(stockname_timeframe)\n",
        "# print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "import joblib\n",
        "\n",
        "model = load_model('./models/nifty_models_5min_sell/NIFTY_5_bilstm_sell_model.keras')\n",
        "model2 = load_model('./models/nifty_models_5min_sell/NIFTY_5_lstm_sell_model.keras')\n",
        "modeld = joblib.load('./models//nifty_models_5min_sell/NIFTY_5_log_sell_model.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X1 = np.array(Xx)\n",
        "y1 = np.array(yx)\n",
        "\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
        "\n",
        "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history = model2.fit(X_train1, y_train1, epochs=20, batch_size=32)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
